{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mid_exam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "10MoNPUBSDSNrx31T8ctb-lWjKgXivrAR",
      "authorship_tag": "ABX9TyPVfuOiVadUgj5HcwUKJt97"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEzgGGEYOfty",
        "colab_type": "code",
        "outputId": "17bd71b7-569b-4e5d-c076-c84a5dc5965e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words= set(stopwords.words('english'))\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRPlnfna1y46",
        "colab_type": "text"
      },
      "source": [
        "Task 1: (15 pts.)  \n",
        "Without using anything but the raw json data (i.e., via the variable \"data\", and not the pandas dataframe \"A\"), write code to find the counts of all unique question categories. Your answer should match the above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIJz3raEulzj",
        "colab_type": "code",
        "outputId": "bf42867f-df22-4d22-94ab-8c7b9027e187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Q1\n",
        "import json\n",
        "with open('/content/drive/My Drive/NLP/exam/JEOPARDY_QUESTIONS1.json', 'r') as f:      \n",
        "    rawj = json.load(f) \n",
        "data = pd.DataFrame(rawj)  \n",
        "\n",
        "from collections import Counter  \n",
        "ct=Counter([x['category'] for x in rawj if x.get('category')])#\\'category\\':.*?(?=,)\n",
        "ctm=ct.most_common(len(ct))\n",
        "#ctm[0:20]#for easy read only output 20\n",
        "#for a clean view\n",
        "df_ct = pd.DataFrame.from_dict(ct, orient='index').reset_index().rename(columns={'index':'word', 0:'count'})\n",
        "df_ct.sort_values(by=['count'], ascending=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>BEFORE &amp; AFTER</td>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>LITERATURE</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>AMERICAN HISTORY</td>\n",
              "      <td>418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>POTPOURRI</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22684</th>\n",
              "      <td>1999 TELEVISION</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10761</th>\n",
              "      <td>WORDS IN PHYSICS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13169</th>\n",
              "      <td>LITERATURE &amp; MUSIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17459</th>\n",
              "      <td>'90s NOTABLES</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5895</th>\n",
              "      <td>CELEBRITY NAMES</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27995 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     word  count\n",
              "722        BEFORE & AFTER    547\n",
              "60                SCIENCE    519\n",
              "522            LITERATURE    496\n",
              "152      AMERICAN HISTORY    418\n",
              "188             POTPOURRI    401\n",
              "...                   ...    ...\n",
              "22684     1999 TELEVISION      1\n",
              "10761    WORDS IN PHYSICS      1\n",
              "13169  LITERATURE & MUSIC      1\n",
              "17459       '90s NOTABLES      1\n",
              "5895      CELEBRITY NAMES      1\n",
              "\n",
              "[27995 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__PgsyRF2RE3",
        "colab_type": "text"
      },
      "source": [
        "Task 2: (30 pts.)  \n",
        "Using the pandas dataframe \"A\", write code to see if there is a correlation between question length (in character counts) and the dollar value of the question. Hint: use the Pearson correlation via scipy.stats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi80fcPUfgPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2bc153cb-b0b0-42f0-fa96-5c5e655a0169"
      },
      "source": [
        "data\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>air_date</th>\n",
              "      <th>question</th>\n",
              "      <th>value</th>\n",
              "      <th>answer</th>\n",
              "      <th>round</th>\n",
              "      <th>show_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HISTORY</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
              "      <td>$200</td>\n",
              "      <td>Copernicus</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
              "      <td>$200</td>\n",
              "      <td>Jim Thorpe</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>'The city of Yuma in this state has a record a...</td>\n",
              "      <td>$200</td>\n",
              "      <td>Arizona</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMPANY LINE</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
              "      <td>$200</td>\n",
              "      <td>McDonald\\'s</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
              "      <td>$200</td>\n",
              "      <td>John Adams</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>4680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216925</th>\n",
              "      <td>RIDDLE ME THIS</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>'This Puccini opera turns on the solution to 3...</td>\n",
              "      <td>$2000</td>\n",
              "      <td>Turandot</td>\n",
              "      <td>Double Jeopardy!</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216926</th>\n",
              "      <td>\"T\" BIRDS</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>'In North America this term is properly applie...</td>\n",
              "      <td>$2000</td>\n",
              "      <td>a titmouse</td>\n",
              "      <td>Double Jeopardy!</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216927</th>\n",
              "      <td>AUTHORS IN THEIR YOUTH</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>'In Penny Lane, where this \"Hellraiser\" grew u...</td>\n",
              "      <td>$2000</td>\n",
              "      <td>Clive Barker</td>\n",
              "      <td>Double Jeopardy!</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216928</th>\n",
              "      <td>QUOTATIONS</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>'From Ft. Sill, Okla. he made the plea, Arizon...</td>\n",
              "      <td>$2000</td>\n",
              "      <td>Geronimo</td>\n",
              "      <td>Double Jeopardy!</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216929</th>\n",
              "      <td>HISTORIC NAMES</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>'A silent movie title includes the last name o...</td>\n",
              "      <td>None</td>\n",
              "      <td>Grigori Alexandrovich Potemkin</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>4999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216930 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               category  ... show_number\n",
              "0                               HISTORY  ...        4680\n",
              "1       ESPN's TOP 10 ALL-TIME ATHLETES  ...        4680\n",
              "2           EVERYBODY TALKS ABOUT IT...  ...        4680\n",
              "3                      THE COMPANY LINE  ...        4680\n",
              "4                   EPITAPHS & TRIBUTES  ...        4680\n",
              "...                                 ...  ...         ...\n",
              "216925                   RIDDLE ME THIS  ...        4999\n",
              "216926                        \"T\" BIRDS  ...        4999\n",
              "216927           AUTHORS IN THEIR YOUTH  ...        4999\n",
              "216928                       QUOTATIONS  ...        4999\n",
              "216929                   HISTORIC NAMES  ...        4999\n",
              "\n",
              "[216930 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_1RW6mwokBj",
        "colab_type": "code",
        "outputId": "62e7b5e7-6dda-4ba2-9844-ab45839dcba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Q2\n",
        "data1=data\n",
        "data1['value1'] = data['value'].str.extract('\\$(\\d+)', expand=False).astype(float)#clean digital\n",
        "data1[\"question_clean\"]=data1[\"question\"].str.replace(r'[^\\w\\s]+', '')#remove Punctuation\n",
        "data1[\"length\"]= data1[\"question_clean\"].str.len() \n",
        "#data1=data1.fillna(900)\n",
        "data1=data1.dropna()\n",
        "from scipy.stats import pearsonr\n",
        "x = np.asarray(data1['value1'])\n",
        "y = np.asarray(data1['length'])\n",
        "print(pearsonr(x,y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.11132949666855818, 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BazDtJCu2Xy6",
        "colab_type": "text"
      },
      "source": [
        "r=0.111,p-value=0, p value is very small, we may reject H0 there a liitle connection between character len and value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynrFzCPv6gmZ",
        "colab_type": "text"
      },
      "source": [
        "Task 3: (20 pts.)\n",
        "Write code to count the number of adjectives that begin with a vowel contained in all questions asked in 2006."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiCIhRdgWhF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#q3\n",
        "def getlen(x):\n",
        "  x=x.lower()\n",
        "  tags = set(['JJ', 'JJR', 'JJS'])\n",
        "  x=word_tokenize(x)\n",
        "  #print(x)\n",
        "  pos_tags =nltk.pos_tag(x)\n",
        "  #print(pos_tags)\n",
        "  ret = []\n",
        "  for word,pos in pos_tags:\n",
        "    if (pos in tags and re.match(\"^[a|e|i|o|u]\",word)):\n",
        "      ret.append(word)\n",
        "  #print(ret)\n",
        "  return(len(ret))\n",
        "data2006=data.loc[(data['air_date'].str.startswith('2006'))].reset_index(drop=True)\n",
        "data2006[\"adj_vow\"]=data2006[\"question\"].apply(lambda x :getlen(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_ZhyqeqSUC",
        "colab_type": "code",
        "outputId": "9e8956a6-0953-4723-eed9-aa55368f314a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total=sum(data2006[\"adj_vow\"])\n",
        "total"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3860"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PArKBHRn6-kN",
        "colab_type": "text"
      },
      "source": [
        "Task 4: (35 pts.)  \n",
        "Train two binary classification models to predict whether or not a question is either a LITERATURE or SCIENCE question, using the k-nearest neighbor classifier and the ridge classifier.\n",
        "\n",
        "Report out-of-sample accuracy, recall, precision, and f1 scores of both models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZplNULCMZkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Q4\n",
        "knntest=data[['question','category']]\n",
        "\n",
        "#may not use\n",
        "def clean_text(croup):\n",
        "  x=word_tokenize(croup)\n",
        "  clean_senteces=pd.Series(x).str.replace(\"[^a-zA-Z0-9]\",\" \")\n",
        "  clean_senteces=[s.lower() for s in clean_senteces]\n",
        "  text_no_sp=[]\n",
        "  for r in clean_senteces:\n",
        "    tmp=r.split()\n",
        "    sen_new=\" \".join([i for i in tmp if i not in stop_words ])\n",
        "    #sen_new=\" \".join([i for i in tmp])\n",
        "    if len(sen_new)>0:\n",
        "      text_no_sp.append(sen_new)\n",
        "  text_no_sp=\" \".join(text_no_sp)\n",
        "  return(text_no_sp)\n",
        "  #return (clean_senteces)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4efsamh-tkE",
        "colab_type": "code",
        "outputId": "c0f49511-acb5-4d68-bc69-fe93dd709807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#knntest[\"question1\"]=knntest[\"question\"].apply(lambda x :clean_text(x))\n",
        "#knntest=knntest.loc[knntest['category']==\"SCIENCE\"].reset_index(drop=True)\n",
        "knn=knntest.loc[knntest['category'].isin(['SCIENCE','LITERATURE'])  ].reset_index(drop=True)\n",
        "knntest_label=np.asarray(knn[\"category\"])\n",
        "knn[\"question_cl\"]=knn[\"question\"].apply(lambda x :clean_text(x))\n",
        "len(knn)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfeSfs4sA5ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "v = TfidfVectorizer(stop_words=set(stop_words))\n",
        "knntest_set = v.fit_transform(knn[\"question_cl\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCHqksDTF7sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import neighbors     \n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=3, algorithm='auto', weights='distance', n_jobs=1)\n",
        "knn.fit(knntest_set[0:900],knntest_label[0:900])\n",
        "pred_label=knn.predict(knntest_set[900:1000])\n",
        "insamp=knn.predict(knntest_set[0:900])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSAtzmBqY-68",
        "colab_type": "code",
        "outputId": "4678b970-c730-4120-e2d5-fc1bf54e0ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "def metrics_result(actual, predict):\n",
        "  print('precision:{0:.3f}'.format(metrics.precision_score(actual, predict, average='weighted')))\n",
        "  print('recall:{0:0.3f}'.format(metrics.recall_score(actual, predict, average='weighted')))\n",
        "  print('f1-score:{0:.3f}'.format(metrics.f1_score(actual, predict, average='weighted')))\n",
        "print(\"KNN:train:0~900,test:900~1000\")\n",
        "print(\"=======out of sample========\")\n",
        "metrics_result(knntest_label[900:1000], pred_label)\n",
        "print(\"==========in sample==========\")\n",
        "metrics_result(knntest_label[0:900], insamp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:0~900,test:900~1000\n",
            "=======out of sample========\n",
            "precision:0.890\n",
            "recall:0.890\n",
            "f1-score:0.890\n",
            "==========in sample==========\n",
            "precision:1.000\n",
            "recall:1.000\n",
            "f1-score:1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOkIa0ylrzhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rilabel=[]\n",
        "for i in knntest_label:\n",
        "  if i==\"SCIENCE\":\n",
        "    rilabel.append(0)#sci to 0\n",
        "  else:\n",
        "    rilabel.append(1)\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "clf =RidgeClassifier()\n",
        "clf.fit(knntest_set[0:900],rilabel[0:900]) \n",
        "clfpre=clf.predict(knntest_set[900:1000])\n",
        "incl=clf.predict(knntest_set[0:900])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGeu_Cb00tYV",
        "colab_type": "code",
        "outputId": "1809ba3a-0d1a-4816-ce87-2306bb16fa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(\"ridge:train:0~900,test:900~1000\")\n",
        "print(\"=======out of sample========\")\n",
        "metrics_result(rilabel[900:1000], clfpre)\n",
        "print(\"==========in sample==========\")\n",
        "metrics_result(rilabel[0:900], incl)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:0~900,test:900~1000\n",
            "=======out of sample========\n",
            "precision:0.961\n",
            "recall:0.960\n",
            "f1-score:0.960\n",
            "==========in sample==========\n",
            "precision:1.000\n",
            "recall:1.000\n",
            "f1-score:1.000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}